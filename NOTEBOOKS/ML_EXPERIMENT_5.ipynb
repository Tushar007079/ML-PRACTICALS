{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Student Name: Tushar Panchal***\n",
        "\n",
        "# ***En. No. : 21162101014***\n",
        "\n",
        "# ***Branch: CBA***\n",
        "\n",
        "# ***Batch:  71***\n",
        "\n",
        "# ***Subject: ML (Machine Learning)***"
      ],
      "metadata": {
        "id": "VBSVLX2O79nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXPERIMENT 5**\n",
        "# Credit Card Default Prediction\n"
      ],
      "metadata": {
        "id": "-6ytBEjy77pO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Instructions**:\n",
        "Financial threats are displaying a trend about the credit risk of commercial banks as the\n",
        "incredible improvement in the financial industry has arisen. In this way, one of the\n",
        "biggest threats faces by commercial banks is the risk prediction of credit clients. The\n",
        "goal is to predict the probability of credit default based on credit card owner's\n",
        "characteristics and payment history.\n",
        "\n",
        "**Approach**: The classical machine learning tasks like Data Exploration, Data Cleaning,\n",
        "Feature Engineering, Model Building and Model Testing. Try out different machine\n",
        "learning algorithms that’s best fit for the above case.\n",
        "\n",
        "**Results**: You have to build a solution that should able to predict the probability of credit\n",
        "default based on credit card owner’s characteristics and payment history.\n",
        "\n",
        "**Dataset**: https://www.kaggle.com/datasets/uciml/default-of-credit-card-clients-dataset\n",
        "\n",
        "Try different classification models and justify which one is best using any accuracy measures.\n"
      ],
      "metadata": {
        "id": "Qw5w0wPOs5cL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORT** **DATASETS**"
      ],
      "metadata": {
        "id": "G840ZxKQ14Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOGIZbAKsDpR",
        "outputId": "4b4779e9-ca1b-4831-984f-34a8623d74eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/ML_DATASETS/ML_5/UCI_Credit_Card.csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWDjeOpMrSxB",
        "outputId": "d9b520e4-922d-4898-87fd-d056b264c160"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
            "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
            "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
            "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
            "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
            "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
            "\n",
            "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
            "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
            "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
            "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
            "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
            "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
            "\n",
            "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
            "0       0.0       0.0       0.0                           1  \n",
            "1    1000.0       0.0    2000.0                           1  \n",
            "2    1000.0    1000.0    5000.0                           0  \n",
            "3    1100.0    1069.0    1000.0                           0  \n",
            "4    9000.0     689.0     679.0                           0  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values in each column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values if any (if necessary)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Convert categorical variables to numeric using one-hot encoding if needed\n",
        "df = pd.get_dummies(df, columns=['SEX', 'EDUCATION', 'MARRIAGE'], drop_first=True)\n",
        "\n",
        "# Verify changes\n",
        "print(\"Data after processing:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_ywqAS6sXmv",
        "outputId": "3b63bcc7-36fc-46d7-96ac-5b129b979565"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "ID                            0\n",
            "LIMIT_BAL                     0\n",
            "SEX                           0\n",
            "EDUCATION                     0\n",
            "MARRIAGE                      0\n",
            "AGE                           0\n",
            "PAY_0                         0\n",
            "PAY_2                         0\n",
            "PAY_3                         0\n",
            "PAY_4                         0\n",
            "PAY_5                         0\n",
            "PAY_6                         0\n",
            "BILL_AMT1                     0\n",
            "BILL_AMT2                     0\n",
            "BILL_AMT3                     0\n",
            "BILL_AMT4                     0\n",
            "BILL_AMT5                     0\n",
            "BILL_AMT6                     0\n",
            "PAY_AMT1                      0\n",
            "PAY_AMT2                      0\n",
            "PAY_AMT3                      0\n",
            "PAY_AMT4                      0\n",
            "PAY_AMT5                      0\n",
            "PAY_AMT6                      0\n",
            "default.payment.next.month    0\n",
            "dtype: int64\n",
            "Data after processing:\n",
            "   ID  LIMIT_BAL  AGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  BILL_AMT1  \\\n",
            "0   1    20000.0   24      2      2     -1     -1     -2     -2     3913.0   \n",
            "1   2   120000.0   26     -1      2      0      0      0      2     2682.0   \n",
            "2   3    90000.0   34      0      0      0      0      0      0    29239.0   \n",
            "3   4    50000.0   37      0      0      0      0      0      0    46990.0   \n",
            "4   5    50000.0   57     -1      0     -1      0      0      0     8617.0   \n",
            "\n",
            "   ...  SEX_2  EDUCATION_1  EDUCATION_2  EDUCATION_3  EDUCATION_4  \\\n",
            "0  ...   True        False         True        False        False   \n",
            "1  ...   True        False         True        False        False   \n",
            "2  ...   True        False         True        False        False   \n",
            "3  ...   True        False         True        False        False   \n",
            "4  ...  False        False         True        False        False   \n",
            "\n",
            "   EDUCATION_5  EDUCATION_6  MARRIAGE_1  MARRIAGE_2  MARRIAGE_3  \n",
            "0        False        False        True       False       False  \n",
            "1        False        False       False        True       False  \n",
            "2        False        False       False        True       False  \n",
            "3        False        False        True       False       False  \n",
            "4        False        False        True       False       False  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['ID', 'default.payment.next.month'])  # Features\n",
        "y = df['default.payment.next.month']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and fit the logistic regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate the model\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt71qnIashs_",
        "outputId": "7150ac99-78c6-4563-88dc-aa9b030b0f69"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.88      7040\n",
            "           1       0.65      0.20      0.31      1960\n",
            "\n",
            "    accuracy                           0.80      9000\n",
            "   macro avg       0.73      0.59      0.60      9000\n",
            "weighted avg       0.78      0.80      0.76      9000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize and fit the KNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate the model\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"K-Nearest Neighbors Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnxRiZa1sx0H",
        "outputId": "b1522aa6-082c-416c-e1dc-30a16662016b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Nearest Neighbors Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85      7040\n",
            "           1       0.36      0.17      0.23      1960\n",
            "\n",
            "    accuracy                           0.75      9000\n",
            "   macro avg       0.58      0.54      0.54      9000\n",
            "weighted avg       0.70      0.75      0.72      9000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize and fit the decision tree model\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate the model\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Decision Tree Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_dt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOgJaOLytDnH",
        "outputId": "8238cf09-ebc8-45e9-db73-7f3688ff7a48"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82      7040\n",
            "           1       0.38      0.41      0.39      1960\n",
            "\n",
            "    accuracy                           0.72      9000\n",
            "   macro avg       0.60      0.61      0.61      9000\n",
            "weighted avg       0.73      0.72      0.73      9000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import jaccard_score, confusion_matrix, precision_recall_fscore_support, log_loss, classification_report\n",
        "\n",
        "# Compute evaluation metrics for Logistic Regression\n",
        "print(\"Logistic Regression Evaluation Metrics:\")\n",
        "print(\"Jaccard Score:\", jaccard_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', zero_division=0)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "print(\"Log Loss:\", log_loss(y_test, logreg.predict_proba(X_test)))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# Compute evaluation metrics for K-Nearest Neighbors\n",
        "print(\"\\nk-Nearest Neighbors Evaluation Metrics:\")\n",
        "print(\"Jaccard Score:\", jaccard_score(y_test, y_pred_knn))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_knn))\n",
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_knn, average='binary', zero_division=0)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "print(\"Log Loss:\", log_loss(y_test, knn.predict_proba(X_test)))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_knn, zero_division=0))\n",
        "\n",
        "# Compute evaluation metrics for Decision Tree\n",
        "print(\"\\nDecision Tree Evaluation Metrics:\")\n",
        "print(\"Jaccard Score:\", jaccard_score(y_test, y_pred_dt))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))\n",
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_dt, average='binary', zero_division=0)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "print(\"Log Loss:\", log_loss(y_test, dt.predict_proba(X_test)))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_dt, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B0M4QO8tQW_",
        "outputId": "61602f67-0cd9-4227-8abf-0616cbe3c358"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Evaluation Metrics:\n",
            "Jaccard Score: 0.18064516129032257\n",
            "Confusion Matrix:\n",
            " [[6830  210]\n",
            " [1568  392]]\n",
            "Precision: 0.6511627906976745\n",
            "Recall: 0.2\n",
            "F1 Score: 0.30601092896174864\n",
            "Log Loss: 0.48189313395142935\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.88      7040\n",
            "           1       0.65      0.20      0.31      1960\n",
            "\n",
            "    accuracy                           0.80      9000\n",
            "   macro avg       0.73      0.59      0.60      9000\n",
            "weighted avg       0.78      0.80      0.76      9000\n",
            "\n",
            "\n",
            "k-Nearest Neighbors Evaluation Metrics:\n",
            "Jaccard Score: 0.13237016790316283\n",
            "Confusion Matrix:\n",
            " [[6439  601]\n",
            " [1621  339]]\n",
            "Precision: 0.3606382978723404\n",
            "Recall: 0.17295918367346938\n",
            "F1 Score: 0.23379310344827586\n",
            "Log Loss: 2.3165278164776297\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85      7040\n",
            "           1       0.36      0.17      0.23      1960\n",
            "\n",
            "    accuracy                           0.75      9000\n",
            "   macro avg       0.58      0.54      0.54      9000\n",
            "weighted avg       0.70      0.75      0.72      9000\n",
            "\n",
            "\n",
            "Decision Tree Evaluation Metrics:\n",
            "Jaccard Score: 0.24430955993930198\n",
            "Confusion Matrix:\n",
            " [[5705 1335]\n",
            " [1155  805]]\n",
            "Precision: 0.37616822429906543\n",
            "Recall: 0.4107142857142857\n",
            "F1 Score: 0.3926829268292683\n",
            "Log Loss: 9.96052498464641\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82      7040\n",
            "           1       0.38      0.41      0.39      1960\n",
            "\n",
            "    accuracy                           0.72      9000\n",
            "   macro avg       0.60      0.61      0.61      9000\n",
            "weighted avg       0.73      0.72      0.73      9000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}